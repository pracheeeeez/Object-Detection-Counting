{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T3x8OwnsS1f-",
        "outputId": "8b87c6c9-cb05-4587-c0dd-1af29ef41d12"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun Dec 15 16:26:53 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   56C    P8              10W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "! nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8CY1pW_RS_T4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "HOME = os.getcwd()\n",
        "print(HOME)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2JtOefnyTwQ4",
        "outputId": "99696b2f-a3a2-46f3-ecce-59b01f5e7ece"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install \"ultralytics<=8.3.40\" supervision roboflow\n",
        "import ultralytics\n",
        "ultralytics.checks()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OaNmhTijT170",
        "outputId": "ac31917f-6f6e-441a-fe7a-152b2a6f5e71"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.40 🚀 Python-3.10.12 torch-2.5.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "Setup complete ✅ (2 CPUs, 12.7 GB RAM, 32.7/112.6 GB disk)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install roboflow\n",
        "\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"G3gy8CV2o0N6SaOoF00a\")\n",
        "project = rf.workspace(\"moyed-chowdhury\").project(\"mv_train_data\")\n",
        "version = project.version(2)\n",
        "dataset = version.download(\"yolov8\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P7deOavhVD1z",
        "outputId": "462fb580-b76d-45b0-9c48-b2d7a6085533"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: roboflow in /usr/local/lib/python3.10/dist-packages (1.1.50)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from roboflow) (2024.8.30)\n",
            "Requirement already satisfied: idna==3.7 in /usr/local/lib/python3.10/dist-packages (from roboflow) (3.7)\n",
            "Requirement already satisfied: cycler in /usr/local/lib/python3.10/dist-packages (from roboflow) (0.12.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.4.7)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from roboflow) (3.8.0)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.26.4)\n",
            "Requirement already satisfied: opencv-python-headless==4.10.0.84 in /usr/local/lib/python3.10/dist-packages (from roboflow) (4.10.0.84)\n",
            "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from roboflow) (11.0.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.8.2)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.0.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.32.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.17.0)\n",
            "Requirement already satisfied: urllib3>=1.26.6 in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.2.3)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from roboflow) (4.66.6)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from roboflow) (6.0.2)\n",
            "Requirement already satisfied: requests-toolbelt in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.0.0)\n",
            "Requirement already satisfied: filetype in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.2.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (1.3.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (4.55.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (3.2.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->roboflow) (3.4.0)\n",
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading Dataset Version Zip in MV_Train_Data-2 to yolov8:: 100%|██████████| 77807/77807 [00:01<00:00, 41103.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Extracting Dataset Version Zip to MV_Train_Data-2 in yolov8:: 100%|██████████| 2710/2710 [00:00<00:00, 5540.35it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install supervision==0.1.0\n",
        "! pip install opencv-python"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "luQIhhbhUcm6",
        "outputId": "9cae02ef-19b9-4dd4-945c-a8a6920dfc3a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting supervision==0.1.0\n",
            "  Downloading supervision-0.1.0-py3-none-any.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from supervision==0.1.0) (1.26.4)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from supervision==0.1.0) (4.10.0.84)\n",
            "Downloading supervision-0.1.0-py3-none-any.whl (14 kB)\n",
            "Installing collected packages: supervision\n",
            "  Attempting uninstall: supervision\n",
            "    Found existing installation: supervision 0.25.1\n",
            "    Uninstalling supervision-0.25.1:\n",
            "      Successfully uninstalled supervision-0.25.1\n",
            "Successfully installed supervision-0.1.0\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python) (1.26.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!yolo task=detect mode=train model=yolov8s.pt data=/content/MV_Train_Data-2/data.yaml epochs=25 imgsz=640 batch=16 workers=8 --half --cache\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9nkJnY9oU96K",
        "outputId": "cfef06d0-5178-4c1f-b0b2-c305125b0ab4"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING ⚠️ argument '--half' does not require leading dashes '--', updating to 'half'.\n",
            "WARNING ⚠️ argument '--cache' does not require leading dashes '--', updating to 'cache'.\n",
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8s.pt to 'yolov8s.pt'...\n",
            "100% 21.5M/21.5M [00:00<00:00, 251MB/s]\n",
            "New https://pypi.org/project/ultralytics/8.3.49 available 😃 Update with 'pip install -U ultralytics'\n",
            "Ultralytics 8.3.40 🚀 Python-3.10.12 torch-2.5.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8s.pt, data=/content/MV_Train_Data-2/data.yaml, epochs=25, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=True, device=None, workers=8, project=None, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=True, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n",
            "100% 755k/755k [00:00<00:00, 23.1MB/s]\n",
            "Overriding model.yaml nc=80 with nc=2\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
            "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
            "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
            "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
            "  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n",
            "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n",
            " 22        [15, 18, 21]  1   2116822  ultralytics.nn.modules.head.Detect           [2, [128, 256, 512]]          \n",
            "Model summary: 225 layers, 11,136,374 parameters, 11,136,358 gradients, 28.6 GFLOPs\n",
            "\n",
            "Transferred 349/355 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train', view at http://localhost:6006/\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt'...\n",
            "100% 5.35M/5.35M [00:00<00:00, 88.4MB/s]\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/MV_Train_Data-2/train/labels... 944 images, 7 backgrounds, 0 corrupt: 100% 944/944 [00:00<00:00, 1884.84it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/MV_Train_Data-2/train/labels.cache\n",
            "WARNING ⚠️ cache='ram' may produce non-deterministic training results. Consider cache='disk' as a deterministic alternative if your disk space allows.\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (1.1GB RAM): 100% 944/944 [00:02<00:00, 370.78it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/albumentations/__init__.py:24: UserWarning: A new version of Albumentations is available: 1.4.22 (you have 1.4.20). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
            "  check_for_updates()\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/MV_Train_Data-2/valid/labels... 268 images, 4 backgrounds, 0 corrupt: 100% 268/268 [00:00<00:00, 849.08it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/MV_Train_Data-2/valid/labels.cache\n",
            "WARNING ⚠️ cache='ram' may produce non-deterministic training results. Consider cache='disk' as a deterministic alternative if your disk space allows.\n",
            "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.3GB RAM): 100% 268/268 [00:01<00:00, 139.12it/s]\n",
            "Plotting labels to runs/detect/train/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001667, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/detect/train\u001b[0m\n",
            "Starting training for 25 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       1/25      4.08G     0.6553      1.269      1.021         73        640: 100% 59/59 [00:20<00:00,  2.89it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 9/9 [00:05<00:00,  1.73it/s]\n",
            "                   all        268        779      0.869      0.799      0.847      0.715\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       2/25      3.89G     0.5936     0.5924     0.9693         69        640: 100% 59/59 [00:18<00:00,  3.19it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 9/9 [00:02<00:00,  3.90it/s]\n",
            "                   all        268        779      0.863      0.762      0.808      0.698\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       3/25      3.87G     0.6105     0.5576     0.9726         74        640: 100% 59/59 [00:18<00:00,  3.21it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 9/9 [00:02<00:00,  3.96it/s]\n",
            "                   all        268        779      0.923      0.934      0.954      0.807\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       4/25      3.88G     0.5936     0.5192     0.9644         64        640: 100% 59/59 [00:18<00:00,  3.15it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 9/9 [00:03<00:00,  2.80it/s]\n",
            "                   all        268        779      0.879      0.825      0.844      0.722\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       5/25      3.86G     0.5693     0.4883     0.9464         89        640: 100% 59/59 [00:18<00:00,  3.13it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 9/9 [00:02<00:00,  3.54it/s]\n",
            "                   all        268        779      0.933      0.955      0.969      0.854\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       6/25      4.04G     0.5455      0.458     0.9482         62        640: 100% 59/59 [00:18<00:00,  3.19it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 9/9 [00:02<00:00,  3.97it/s]\n",
            "                   all        268        779      0.941      0.942      0.958       0.84\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       7/25      4.05G     0.5211      0.435     0.9355         64        640: 100% 59/59 [00:18<00:00,  3.21it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 9/9 [00:02<00:00,  3.26it/s]\n",
            "                   all        268        779      0.935      0.929      0.965      0.873\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       8/25      4.04G     0.5156     0.4121     0.9377         67        640: 100% 59/59 [00:18<00:00,  3.23it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 9/9 [00:03<00:00,  2.64it/s]\n",
            "                   all        268        779      0.942      0.925      0.969      0.868\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       9/25      3.97G     0.5071     0.4226     0.9282         76        640: 100% 59/59 [00:18<00:00,  3.23it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 9/9 [00:02<00:00,  3.86it/s]\n",
            "                   all        268        779       0.96      0.947      0.972      0.881\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      10/25      3.89G     0.4759     0.3837     0.9142        101        640: 100% 59/59 [00:18<00:00,  3.22it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 9/9 [00:02<00:00,  3.98it/s]\n",
            "                   all        268        779      0.954      0.945      0.976      0.884\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      11/25      3.91G     0.4802     0.3885     0.9176         71        640: 100% 59/59 [00:18<00:00,  3.16it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 9/9 [00:03<00:00,  2.37it/s]\n",
            "                   all        268        779       0.97      0.936      0.977       0.89\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      12/25      3.88G     0.4662     0.3893     0.9138         64        640: 100% 59/59 [00:18<00:00,  3.18it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 9/9 [00:02<00:00,  3.96it/s]\n",
            "                   all        268        779      0.947      0.954      0.973      0.896\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      13/25      3.86G     0.4498     0.3657     0.9068         61        640: 100% 59/59 [00:18<00:00,  3.25it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 9/9 [00:02<00:00,  3.90it/s]\n",
            "                   all        268        779      0.955      0.954      0.969      0.896\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      14/25      3.89G      0.461     0.3736     0.9136         57        640: 100% 59/59 [00:18<00:00,  3.21it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 9/9 [00:03<00:00,  2.76it/s]\n",
            "                   all        268        779      0.946      0.964      0.972      0.897\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      15/25      4.04G     0.4403     0.3523     0.9052         64        640: 100% 59/59 [00:18<00:00,  3.18it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 9/9 [00:02<00:00,  3.58it/s]\n",
            "                   all        268        779      0.955      0.958      0.977        0.9\n",
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      16/25      4.04G      0.437       0.34     0.8908         46        640: 100% 59/59 [00:19<00:00,  2.99it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 9/9 [00:02<00:00,  3.96it/s]\n",
            "                   all        268        779      0.953      0.964      0.975      0.905\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      17/25         4G     0.4361     0.3378     0.8968         46        640: 100% 59/59 [00:18<00:00,  3.24it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 9/9 [00:02<00:00,  3.53it/s]\n",
            "                   all        268        779       0.93      0.961      0.974      0.902\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      18/25      4.02G     0.4221      0.329      0.889         46        640: 100% 59/59 [00:17<00:00,  3.29it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 9/9 [00:03<00:00,  2.55it/s]\n",
            "                   all        268        779      0.952      0.963      0.975      0.909\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      19/25      4.04G     0.4052     0.3236     0.8813         51        640: 100% 59/59 [00:17<00:00,  3.30it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 9/9 [00:03<00:00,  2.89it/s]\n",
            "                   all        268        779      0.957      0.952      0.975      0.914\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      20/25      4.03G     0.4025      0.317     0.8748         47        640: 100% 59/59 [00:18<00:00,  3.27it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 9/9 [00:02<00:00,  3.92it/s]\n",
            "                   all        268        779      0.943      0.962      0.971       0.91\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      21/25         4G     0.3931     0.3078     0.8812         44        640: 100% 59/59 [00:18<00:00,  3.27it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 9/9 [00:02<00:00,  3.98it/s]\n",
            "                   all        268        779      0.946      0.969      0.979       0.92\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      22/25      4.02G     0.3885     0.3041     0.8686         43        640: 100% 59/59 [00:17<00:00,  3.39it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 9/9 [00:03<00:00,  2.68it/s]\n",
            "                   all        268        779      0.952      0.955      0.978      0.922\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      23/25      3.87G     0.3729     0.2818     0.8612         43        640: 100% 59/59 [00:17<00:00,  3.38it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 9/9 [00:03<00:00,  2.77it/s]\n",
            "                   all        268        779      0.957      0.949      0.973      0.919\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      24/25      4.03G     0.3632     0.2809     0.8571         41        640: 100% 59/59 [00:18<00:00,  3.24it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 9/9 [00:02<00:00,  3.91it/s]\n",
            "                   all        268        779      0.956      0.964      0.978      0.925\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      25/25         4G     0.3574     0.2684     0.8603         43        640: 100% 59/59 [00:18<00:00,  3.25it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 9/9 [00:02<00:00,  3.98it/s]\n",
            "                   all        268        779       0.96      0.959      0.978      0.927\n",
            "\n",
            "25 epochs completed in 0.155 hours.\n",
            "Optimizer stripped from runs/detect/train/weights/last.pt, 22.5MB\n",
            "Optimizer stripped from runs/detect/train/weights/best.pt, 22.5MB\n",
            "\n",
            "Validating runs/detect/train/weights/best.pt...\n",
            "Ultralytics 8.3.40 🚀 Python-3.10.12 torch-2.5.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "Model summary (fused): 168 layers, 11,126,358 parameters, 0 gradients, 28.4 GFLOPs\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 9/9 [00:06<00:00,  1.48it/s]\n",
            "                   all        268        779      0.959      0.959      0.978      0.927\n",
            "      EnergyPlus_Large        148        180      0.947       0.95       0.97      0.912\n",
            "        EnergyPlus_Reg        257        599      0.972      0.968      0.985      0.941\n",
            "Speed: 0.3ms preprocess, 4.8ms inference, 0.0ms loss, 4.4ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/train\u001b[0m\n",
            "💡 Learn more at https://docs.ultralytics.com/modes/train\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! yolo task=detect mode=val model=/content/runs/detect/train/weights/best.pt data= /content/MV_Train_Data-2/data.yaml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o82jj0eVn2gZ",
        "outputId": "9aa94045-317a-4b35-fd05-60482f9abb4b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.40 🚀 Python-3.10.12 torch-2.5.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "Model summary (fused): 168 layers, 11,126,358 parameters, 0 gradients, 28.4 GFLOPs\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/MV_Train_Data-2/valid/labels.cache... 268 images, 4 backgrounds, 0 corrupt: 100% 268/268 [00:00<?, ?it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 17/17 [00:06<00:00,  2.53it/s]\n",
            "                   all        268        779       0.96      0.959      0.978      0.927\n",
            "      EnergyPlus_Large        148        180      0.948       0.95       0.97      0.913\n",
            "        EnergyPlus_Reg        257        599      0.972      0.968      0.985      0.941\n",
            "Speed: 0.9ms preprocess, 10.7ms inference, 0.0ms loss, 3.9ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/val\u001b[0m\n",
            "💡 Learn more at https://docs.ultralytics.com/modes/val\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!yolo task=detect mode=predict model= /content/runs/detect/train/weights/best.pt conf=0.25 source={dataset.location}/test/images save=True"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "soihNe5xn4b4",
        "outputId": "a16f2cd8-a81a-4b68-e3ef-bcdd1f9113c1",
        "collapsed": true
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.40 🚀 Python-3.10.12 torch-2.5.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "Model summary (fused): 168 layers, 11,126,358 parameters, 0 gradients, 28.4 GFLOPs\n",
            "\n",
            "image 1/137 /content/MV_Train_Data-2/test/images/Energy-00021_jpg.rf.d6adf67812c4e082b8a7762551d4820e.jpg: 640x640 2 EnergyPlus_Larges, 2 EnergyPlus_Regs, 16.3ms\n",
            "image 2/137 /content/MV_Train_Data-2/test/images/Energy-00076_jpg.rf.65cf6adca53cbda089bf1031dd3b3111.jpg: 640x640 2 EnergyPlus_Larges, 1 EnergyPlus_Reg, 16.3ms\n",
            "image 3/137 /content/MV_Train_Data-2/test/images/Energy-00136_jpg.rf.9f0b647935d4c3de5db36378a073a988.jpg: 640x640 3 EnergyPlus_Larges, 1 EnergyPlus_Reg, 16.2ms\n",
            "image 4/137 /content/MV_Train_Data-2/test/images/Energy-00161_jpg.rf.aa273488721ae01a215bc37d0cfce239.jpg: 640x640 2 EnergyPlus_Larges, 1 EnergyPlus_Reg, 16.2ms\n",
            "image 5/137 /content/MV_Train_Data-2/test/images/Energy-00196_jpg.rf.0dd23fe6701ffdcd1eb23bec2bc23087.jpg: 640x640 1 EnergyPlus_Large, 2 EnergyPlus_Regs, 16.2ms\n",
            "image 6/137 /content/MV_Train_Data-2/test/images/Energy-00261_jpg.rf.69cabd446acbd63140ea5d13e0a4d3f0.jpg: 640x640 2 EnergyPlus_Larges, 2 EnergyPlus_Regs, 16.2ms\n",
            "image 7/137 /content/MV_Train_Data-2/test/images/Energy-00301_jpg.rf.6198c03995ec8ab94f4fe1edd9a01c6c.jpg: 640x640 1 EnergyPlus_Large, 2 EnergyPlus_Regs, 16.2ms\n",
            "image 8/137 /content/MV_Train_Data-2/test/images/Energy-00361_jpg.rf.3229b333e232a9e140d412b4725a52b0.jpg: 640x640 1 EnergyPlus_Large, 2 EnergyPlus_Regs, 16.2ms\n",
            "image 9/137 /content/MV_Train_Data-2/test/images/Energy-00391_jpg.rf.e78d5ff6c55505ca3f203588b18d6898.jpg: 640x640 1 EnergyPlus_Large, 2 EnergyPlus_Regs, 16.2ms\n",
            "image 10/137 /content/MV_Train_Data-2/test/images/Energy-00441_jpg.rf.8037e422e2073f55d2036754602dbbc7.jpg: 640x640 1 EnergyPlus_Large, 2 EnergyPlus_Regs, 10.7ms\n",
            "image 11/137 /content/MV_Train_Data-2/test/images/Energy-00546_jpg.rf.7445cf3603da5d4929f8b7f14894efd5.jpg: 640x640 1 EnergyPlus_Large, 4 EnergyPlus_Regs, 10.7ms\n",
            "image 12/137 /content/MV_Train_Data-2/test/images/Energy-00631_jpg.rf.51304908ee5cbde76b35846f0ec07f03.jpg: 640x640 1 EnergyPlus_Large, 2 EnergyPlus_Regs, 10.7ms\n",
            "image 13/137 /content/MV_Train_Data-2/test/images/Energy-00671_jpg.rf.97ad58540ab2b0a66694bc821a878fe2.jpg: 640x640 1 EnergyPlus_Large, 3 EnergyPlus_Regs, 10.7ms\n",
            "image 14/137 /content/MV_Train_Data-2/test/images/Energy-00811_jpg.rf.2438c34f154e505075f070431be2aef0.jpg: 640x640 1 EnergyPlus_Large, 2 EnergyPlus_Regs, 10.7ms\n",
            "image 15/137 /content/MV_Train_Data-2/test/images/Energy-00941_jpg.rf.ba0125480e1ba6edd5b4892c672f8633.jpg: 640x640 2 EnergyPlus_Regs, 10.7ms\n",
            "image 16/137 /content/MV_Train_Data-2/test/images/Energy-00976_jpg.rf.d071e4ee65a6fb0a0bec0b44172eb501.jpg: 640x640 2 EnergyPlus_Regs, 10.7ms\n",
            "image 17/137 /content/MV_Train_Data-2/test/images/Energy-00991_jpg.rf.0d3308237deea8df8ddbf11e413a5c34.jpg: 640x640 1 EnergyPlus_Reg, 10.7ms\n",
            "image 18/137 /content/MV_Train_Data-2/test/images/Energy-01056_jpg.rf.feeb04227bc6d9c6ef5eb0caff57a950.jpg: 640x640 3 EnergyPlus_Regs, 10.7ms\n",
            "image 19/137 /content/MV_Train_Data-2/test/images/Energy-01246_jpg.rf.5b5c511e9143c513cb9103876aa44c0d.jpg: 640x640 1 EnergyPlus_Large, 3 EnergyPlus_Regs, 10.7ms\n",
            "image 20/137 /content/MV_Train_Data-2/test/images/Energy-01331_jpg.rf.f5189d0086ce06f40a2e36faa9ed412a.jpg: 640x640 2 EnergyPlus_Larges, 2 EnergyPlus_Regs, 10.7ms\n",
            "image 21/137 /content/MV_Train_Data-2/test/images/Energy-01396_jpg.rf.615ce2492922c20c8cd48b982d06d1fd.jpg: 640x640 2 EnergyPlus_Regs, 8.3ms\n",
            "image 22/137 /content/MV_Train_Data-2/test/images/Energy-01406_jpg.rf.009e340981c2a50ea9a7537067bb17bb.jpg: 640x640 2 EnergyPlus_Regs, 7.9ms\n",
            "image 23/137 /content/MV_Train_Data-2/test/images/Energy-01521_jpg.rf.0ef0ab4de48c792546426d6b51606854.jpg: 640x640 1 EnergyPlus_Large, 3 EnergyPlus_Regs, 7.9ms\n",
            "image 24/137 /content/MV_Train_Data-2/test/images/Energy-01531_jpg.rf.f3f850c4010d2aca4735ca35fad48a96.jpg: 640x640 1 EnergyPlus_Large, 3 EnergyPlus_Regs, 7.9ms\n",
            "image 25/137 /content/MV_Train_Data-2/test/images/Energy-01536_jpg.rf.8e70fa9e2ba27e2090d210deb3b5f3bf.jpg: 640x640 1 EnergyPlus_Large, 3 EnergyPlus_Regs, 8.1ms\n",
            "image 26/137 /content/MV_Train_Data-2/test/images/Energy-01546_jpg.rf.afbcc9b2dd26aa6fd9cd4ba50f42c5d6.jpg: 640x640 1 EnergyPlus_Large, 3 EnergyPlus_Regs, 7.9ms\n",
            "image 27/137 /content/MV_Train_Data-2/test/images/Energy-01566_jpg.rf.b1bcca05c4b28ef5534dd0b6fcc2cafd.jpg: 640x640 1 EnergyPlus_Large, 3 EnergyPlus_Regs, 7.9ms\n",
            "image 28/137 /content/MV_Train_Data-2/test/images/Energy-01651_jpg.rf.f5a0d4b5b9572ca42cde7f25433c8d44.jpg: 640x640 4 EnergyPlus_Regs, 7.9ms\n",
            "image 29/137 /content/MV_Train_Data-2/test/images/Energy-01686_jpg.rf.9e82d5a5c8d08b36aecdc9ed99c54495.jpg: 640x640 3 EnergyPlus_Regs, 7.9ms\n",
            "image 30/137 /content/MV_Train_Data-2/test/images/Energy-01721_jpg.rf.fcfcedcee627d55d4c9689fb2493a07c.jpg: 640x640 2 EnergyPlus_Regs, 8.9ms\n",
            "image 31/137 /content/MV_Train_Data-2/test/images/Energy-01896_jpg.rf.d181c7f7f3c93b0cd97e2e9f15143a58.jpg: 640x640 1 EnergyPlus_Large, 3 EnergyPlus_Regs, 7.9ms\n",
            "image 32/137 /content/MV_Train_Data-2/test/images/Energy-02016_jpg.rf.48e1503d1be0e8bc602ac766429fb704.jpg: 640x640 2 EnergyPlus_Larges, 2 EnergyPlus_Regs, 10.4ms\n",
            "image 33/137 /content/MV_Train_Data-2/test/images/Energy-02031_jpg.rf.9e4e94f937b30a7a59959a1c912f5800.jpg: 640x640 2 EnergyPlus_Larges, 2 EnergyPlus_Regs, 7.6ms\n",
            "image 34/137 /content/MV_Train_Data-2/test/images/Energy-02056_jpg.rf.9d042e34957ff90e9b9335c3180fad85.jpg: 640x640 2 EnergyPlus_Larges, 2 EnergyPlus_Regs, 7.5ms\n",
            "image 35/137 /content/MV_Train_Data-2/test/images/Energy-02061_jpg.rf.9121e754ca5ba56c1917b728ef171df1.jpg: 640x640 2 EnergyPlus_Larges, 2 EnergyPlus_Regs, 7.6ms\n",
            "image 36/137 /content/MV_Train_Data-2/test/images/Energy-02066_jpg.rf.86ec26408d1857ba2d4f8ff681704ffe.jpg: 640x640 2 EnergyPlus_Larges, 2 EnergyPlus_Regs, 8.1ms\n",
            "image 37/137 /content/MV_Train_Data-2/test/images/Energy-02076_jpg.rf.87e71dc532d5ab4697d071a9ca853d71.jpg: 640x640 2 EnergyPlus_Larges, 2 EnergyPlus_Regs, 7.9ms\n",
            "image 38/137 /content/MV_Train_Data-2/test/images/Energy-02081_jpg.rf.7e09b9ce7928596a1fd7f297e53ea268.jpg: 640x640 2 EnergyPlus_Larges, 2 EnergyPlus_Regs, 7.8ms\n",
            "image 39/137 /content/MV_Train_Data-2/test/images/Energy-02111_jpg.rf.09ab948db2cda7c996c811573062eefc.jpg: 640x640 2 EnergyPlus_Larges, 2 EnergyPlus_Regs, 7.8ms\n",
            "image 40/137 /content/MV_Train_Data-2/test/images/Energy-02356_jpg.rf.275aae28d2778451b64d4b425ef1a2ca.jpg: 640x640 2 EnergyPlus_Larges, 1 EnergyPlus_Reg, 7.9ms\n",
            "image 41/137 /content/MV_Train_Data-2/test/images/Energy-02411_jpg.rf.e12ba95c1a5fe576cfe849561098dfdf.jpg: 640x640 2 EnergyPlus_Larges, 2 EnergyPlus_Regs, 7.9ms\n",
            "image 42/137 /content/MV_Train_Data-2/test/images/Energy-02436_jpg.rf.6e97c87579fa204a96943d18d112165e.jpg: 640x640 1 EnergyPlus_Large, 3 EnergyPlus_Regs, 7.8ms\n",
            "image 43/137 /content/MV_Train_Data-2/test/images/Energy-02441_jpg.rf.75db3abd642e3706e7dda6466b31ab39.jpg: 640x640 1 EnergyPlus_Large, 3 EnergyPlus_Regs, 7.7ms\n",
            "image 44/137 /content/MV_Train_Data-2/test/images/Energy-02456_jpg.rf.a275b070ceba68a04fd8ece5d35a1d39.jpg: 640x640 1 EnergyPlus_Large, 4 EnergyPlus_Regs, 7.6ms\n",
            "image 45/137 /content/MV_Train_Data-2/test/images/Energy-02481_jpg.rf.2449b2272b7eacb53ce14b0b9621a903.jpg: 640x640 4 EnergyPlus_Regs, 8.2ms\n",
            "image 46/137 /content/MV_Train_Data-2/test/images/Energy-02511_jpg.rf.48cfbe024e62306ab9f69422601540ee.jpg: 640x640 1 EnergyPlus_Large, 4 EnergyPlus_Regs, 8.0ms\n",
            "image 47/137 /content/MV_Train_Data-2/test/images/Energy-02536_jpg.rf.fe6c2fbbe2783c6dcefee9a0e2d20ec7.jpg: 640x640 1 EnergyPlus_Large, 3 EnergyPlus_Regs, 8.0ms\n",
            "image 48/137 /content/MV_Train_Data-2/test/images/Energy-02561_jpg.rf.3df5768d5babc1912dc0caa64d3f000c.jpg: 640x640 1 EnergyPlus_Large, 3 EnergyPlus_Regs, 7.7ms\n",
            "image 49/137 /content/MV_Train_Data-2/test/images/Energy-02606_jpg.rf.38442fa8d93fe643ad137fbe97bdfd64.jpg: 640x640 1 EnergyPlus_Large, 2 EnergyPlus_Regs, 7.9ms\n",
            "image 50/137 /content/MV_Train_Data-2/test/images/Energy-02661_jpg.rf.5552edc40930327fc5b6d4606b3c35d6.jpg: 640x640 1 EnergyPlus_Large, 1 EnergyPlus_Reg, 8.0ms\n",
            "image 51/137 /content/MV_Train_Data-2/test/images/Energy-02696_jpg.rf.fa73feb8b218dfa6ba18e47e791b682f.jpg: 640x640 1 EnergyPlus_Large, 2 EnergyPlus_Regs, 7.8ms\n",
            "image 52/137 /content/MV_Train_Data-2/test/images/Energy-02741_jpg.rf.6adfed5db56adaaab1fb91b6deae487a.jpg: 640x640 2 EnergyPlus_Regs, 7.8ms\n",
            "image 53/137 /content/MV_Train_Data-2/test/images/Energy-02806_jpg.rf.5d7f853f466f592c9647ded753fc661c.jpg: 640x640 3 EnergyPlus_Regs, 7.8ms\n",
            "image 54/137 /content/MV_Train_Data-2/test/images/Energy-02881_jpg.rf.356768b964355e4a6f6d07d43ed6d956.jpg: 640x640 2 EnergyPlus_Regs, 8.2ms\n",
            "image 55/137 /content/MV_Train_Data-2/test/images/Energy-02886_jpg.rf.bb39de445f8b87fa89d33b7f872db1d7.jpg: 640x640 2 EnergyPlus_Regs, 7.9ms\n",
            "image 56/137 /content/MV_Train_Data-2/test/images/Energy-02901_jpg.rf.6beeae6823f15196154a936137be8e2c.jpg: 640x640 2 EnergyPlus_Regs, 7.9ms\n",
            "image 57/137 /content/MV_Train_Data-2/test/images/Energy-02936_jpg.rf.ed9e95a2b1bee5054c6e0fa90d99eea9.jpg: 640x640 3 EnergyPlus_Regs, 7.7ms\n",
            "image 58/137 /content/MV_Train_Data-2/test/images/Energy-02956_jpg.rf.2088fa8415322db8f15fa62e46814150.jpg: 640x640 4 EnergyPlus_Regs, 8.1ms\n",
            "image 59/137 /content/MV_Train_Data-2/test/images/Energy-03011_jpg.rf.0a2219934ab1d0db0a18ffd3e1557d03.jpg: 640x640 3 EnergyPlus_Regs, 7.9ms\n",
            "image 60/137 /content/MV_Train_Data-2/test/images/Energy-03041_jpg.rf.8dc504dff5f88c655e164de3b2ffe856.jpg: 640x640 1 EnergyPlus_Large, 3 EnergyPlus_Regs, 11.9ms\n",
            "image 61/137 /content/MV_Train_Data-2/test/images/Energy-03096_jpg.rf.1f22893db002b803c7c11d88c0d9005f.jpg: 640x640 1 EnergyPlus_Large, 2 EnergyPlus_Regs, 10.3ms\n",
            "image 62/137 /content/MV_Train_Data-2/test/images/Energy-03116_jpg.rf.5cd7e859405b3fbe36c5e51265aaa0b5.jpg: 640x640 1 EnergyPlus_Large, 1 EnergyPlus_Reg, 10.5ms\n",
            "image 63/137 /content/MV_Train_Data-2/test/images/Energy-03126_jpg.rf.394136e5e977a03ea157d34ed2dc8422.jpg: 640x640 1 EnergyPlus_Large, 2 EnergyPlus_Regs, 10.1ms\n",
            "image 64/137 /content/MV_Train_Data-2/test/images/Energy-03171_jpg.rf.3f0adafc5c58b0459534c059de2135f2.jpg: 640x640 1 EnergyPlus_Large, 2 EnergyPlus_Regs, 10.0ms\n",
            "image 65/137 /content/MV_Train_Data-2/test/images/Energy-03181_jpg.rf.bd4aef9d14db58b53c5bf1868a501358.jpg: 640x640 1 EnergyPlus_Large, 2 EnergyPlus_Regs, 7.8ms\n",
            "image 66/137 /content/MV_Train_Data-2/test/images/Energy-03211_jpg.rf.454a04a6a5da74817884c2b84d68bfad.jpg: 640x640 1 EnergyPlus_Large, 2 EnergyPlus_Regs, 10.5ms\n",
            "image 67/137 /content/MV_Train_Data-2/test/images/Energy-03216_jpg.rf.f91d527d35fa79db76ce5d61f79374d1.jpg: 640x640 1 EnergyPlus_Large, 2 EnergyPlus_Regs, 8.8ms\n",
            "image 68/137 /content/MV_Train_Data-2/test/images/Energy-03266_jpg.rf.157652ed8ac2455c1dbd6b19dddbb8e4.jpg: 640x640 2 EnergyPlus_Regs, 7.7ms\n",
            "image 69/137 /content/MV_Train_Data-2/test/images/Energy-03271_jpg.rf.5033292891275eee789c948593e621bc.jpg: 640x640 1 EnergyPlus_Large, 2 EnergyPlus_Regs, 8.4ms\n",
            "image 70/137 /content/MV_Train_Data-2/test/images/Energy-03336_jpg.rf.c6d6f82f12cf701097e1b2348fdb8aa6.jpg: 640x640 1 EnergyPlus_Large, 2 EnergyPlus_Regs, 7.8ms\n",
            "image 71/137 /content/MV_Train_Data-2/test/images/Energy-03471_jpg.rf.2600b610e327359b1aae5cf378b705e3.jpg: 640x640 1 EnergyPlus_Large, 2 EnergyPlus_Regs, 7.6ms\n",
            "image 72/137 /content/MV_Train_Data-2/test/images/Energy-03601_jpg.rf.99e2beec605d137827c17b2a18080512.jpg: 640x640 1 EnergyPlus_Large, 1 EnergyPlus_Reg, 10.4ms\n",
            "image 73/137 /content/MV_Train_Data-2/test/images/Energy-03616_jpg.rf.91d23000e9a888b2ddaf2db1e3fd54ac.jpg: 640x640 1 EnergyPlus_Large, 1 EnergyPlus_Reg, 10.8ms\n",
            "image 74/137 /content/MV_Train_Data-2/test/images/Energy-03621_jpg.rf.32a9feb8ff19359a3518e989504a8f04.jpg: 640x640 1 EnergyPlus_Large, 1 EnergyPlus_Reg, 7.7ms\n",
            "image 75/137 /content/MV_Train_Data-2/test/images/Energy-03721_jpg.rf.98b518354503074b02787a72296acc76.jpg: 640x640 1 EnergyPlus_Large, 3 EnergyPlus_Regs, 7.9ms\n",
            "image 76/137 /content/MV_Train_Data-2/test/images/Energy-03766_jpg.rf.d6e48eba2c4ff696d88fb4af396e51ed.jpg: 640x640 1 EnergyPlus_Large, 2 EnergyPlus_Regs, 8.7ms\n",
            "image 77/137 /content/MV_Train_Data-2/test/images/Energy-03806_jpg.rf.97ee260e4460726b1aa12d56bdd8ecdc.jpg: 640x640 3 EnergyPlus_Regs, 7.6ms\n",
            "image 78/137 /content/MV_Train_Data-2/test/images/Energy-03876_jpg.rf.f4d20df93b3330279ab51eaff12fb7d8.jpg: 640x640 2 EnergyPlus_Regs, 7.5ms\n",
            "image 79/137 /content/MV_Train_Data-2/test/images/Energy-03916_jpg.rf.2633bb702b4ab3da6373aec436d8317d.jpg: 640x640 2 EnergyPlus_Regs, 7.5ms\n",
            "image 80/137 /content/MV_Train_Data-2/test/images/Energy-03921_jpg.rf.96ae024d9ebc4a9464fc735d8733772a.jpg: 640x640 2 EnergyPlus_Regs, 7.6ms\n",
            "image 81/137 /content/MV_Train_Data-2/test/images/Energy-03981_jpg.rf.28ea625dc796ad4f95bbf89507409677.jpg: 640x640 3 EnergyPlus_Regs, 10.4ms\n",
            "image 82/137 /content/MV_Train_Data-2/test/images/Energy-04041_jpg.rf.f1b9826d958e7e1395e605bc6b42a2a1.jpg: 640x640 1 EnergyPlus_Reg, 8.0ms\n",
            "image 83/137 /content/MV_Train_Data-2/test/images/Energy-04051_jpg.rf.3a6544770edee1c9ec6ebd2b6eb124b9.jpg: 640x640 1 EnergyPlus_Reg, 7.9ms\n",
            "image 84/137 /content/MV_Train_Data-2/test/images/Energy-04096_jpg.rf.5713bd071022081de01c5e230ed669a6.jpg: 640x640 1 EnergyPlus_Reg, 7.8ms\n",
            "image 85/137 /content/MV_Train_Data-2/test/images/Energy-04101_jpg.rf.05abeec983d4ebbabf81b1ad20d2826f.jpg: 640x640 1 EnergyPlus_Reg, 7.9ms\n",
            "image 86/137 /content/MV_Train_Data-2/test/images/Energy-04156_jpg.rf.a38cd1e2ff21af5193e75cfebc3895bc.jpg: 640x640 (no detections), 8.0ms\n",
            "image 87/137 /content/MV_Train_Data-2/test/images/Energy-04201_jpg.rf.f17b6236ef7b6027f354b44a5071f2c8.jpg: 640x640 1 EnergyPlus_Reg, 8.0ms\n",
            "image 88/137 /content/MV_Train_Data-2/test/images/Energy-04246_jpg.rf.ad7beb2b14610760b72021265d7f3f46.jpg: 640x640 2 EnergyPlus_Regs, 7.9ms\n",
            "image 89/137 /content/MV_Train_Data-2/test/images/Energy-04296_jpg.rf.76dcc73138b01a364c191fa3187fbf31.jpg: 640x640 3 EnergyPlus_Regs, 13.4ms\n",
            "image 90/137 /content/MV_Train_Data-2/test/images/Energy-04401_jpg.rf.5187ef62bc4a72a4eda57c4a9be50fa8.jpg: 640x640 3 EnergyPlus_Regs, 9.5ms\n",
            "image 91/137 /content/MV_Train_Data-2/test/images/Energy-04451_jpg.rf.126dc3a0ac7cd641d3b899c166158ed7.jpg: 640x640 3 EnergyPlus_Regs, 9.1ms\n",
            "image 92/137 /content/MV_Train_Data-2/test/images/Energy-04681_jpg.rf.1eeb1c6ef7d739c54dcfa5530ffe32a9.jpg: 640x640 2 EnergyPlus_Larges, 2 EnergyPlus_Regs, 7.9ms\n",
            "image 93/137 /content/MV_Train_Data-2/test/images/Energy-04686_jpg.rf.6ed1b3bd76746c9958ab04420f5de3e7.jpg: 640x640 1 EnergyPlus_Large, 2 EnergyPlus_Regs, 7.9ms\n",
            "image 94/137 /content/MV_Train_Data-2/test/images/Energy-04721_jpg.rf.1cd138dcfd86e58c28deb9d9d9b9470f.jpg: 640x640 2 EnergyPlus_Regs, 7.9ms\n",
            "image 95/137 /content/MV_Train_Data-2/test/images/Energy-04816_jpg.rf.d2e244b07621f25b519cadad55f872ff.jpg: 640x640 4 EnergyPlus_Regs, 7.8ms\n",
            "image 96/137 /content/MV_Train_Data-2/test/images/Energy-04851_jpg.rf.1eeb50cac3c5a4501ea9eb2d101d2ae9.jpg: 640x640 3 EnergyPlus_Regs, 8.1ms\n",
            "image 97/137 /content/MV_Train_Data-2/test/images/Energy-04941_jpg.rf.706312656c1cf5609dac201e9fde5a5c.jpg: 640x640 1 EnergyPlus_Large, 4 EnergyPlus_Regs, 7.7ms\n",
            "image 98/137 /content/MV_Train_Data-2/test/images/Energy-05001_jpg.rf.fcfcc758477036998f4f1ae7023488e5.jpg: 640x640 1 EnergyPlus_Large, 3 EnergyPlus_Regs, 7.7ms\n",
            "image 99/137 /content/MV_Train_Data-2/test/images/Energy-05031_jpg.rf.89c9856e163b2f3d17210db3b3b95a15.jpg: 640x640 1 EnergyPlus_Large, 2 EnergyPlus_Regs, 8.0ms\n",
            "image 100/137 /content/MV_Train_Data-2/test/images/Energy-05071_jpg.rf.c2763c53a781cbe41544ea8eab9e84ea.jpg: 640x640 2 EnergyPlus_Larges, 2 EnergyPlus_Regs, 7.8ms\n",
            "image 101/137 /content/MV_Train_Data-2/test/images/Energy-05081_jpg.rf.703233fa9643447eda330e5b22880650.jpg: 640x640 2 EnergyPlus_Larges, 2 EnergyPlus_Regs, 7.8ms\n",
            "image 102/137 /content/MV_Train_Data-2/test/images/Energy-05211_jpg.rf.e5cd84a4169c7574199c273ad291da77.jpg: 640x640 2 EnergyPlus_Larges, 1 EnergyPlus_Reg, 8.5ms\n",
            "image 103/137 /content/MV_Train_Data-2/test/images/Energy-05286_jpg.rf.af14a3931b964caf14cd6cc232915c37.jpg: 640x640 1 EnergyPlus_Large, 2 EnergyPlus_Regs, 8.1ms\n",
            "image 104/137 /content/MV_Train_Data-2/test/images/Energy-05416_jpg.rf.ab7f8326b0d4a36a7d8e37449ec5949d.jpg: 640x640 1 EnergyPlus_Large, 4 EnergyPlus_Regs, 7.5ms\n",
            "image 105/137 /content/MV_Train_Data-2/test/images/Energy-05431_jpg.rf.67e838b0474584f12edca58a7ab0f25b.jpg: 640x640 1 EnergyPlus_Large, 3 EnergyPlus_Regs, 11.0ms\n",
            "image 106/137 /content/MV_Train_Data-2/test/images/Energy-05436_jpg.rf.fe50f34ef8dd663d0609388d8ec7b120.jpg: 640x640 1 EnergyPlus_Large, 3 EnergyPlus_Regs, 10.3ms\n",
            "image 107/137 /content/MV_Train_Data-2/test/images/Energy-05446_jpg.rf.d6e31562946366e5559caaa7d3b61d88.jpg: 640x640 1 EnergyPlus_Large, 3 EnergyPlus_Regs, 7.5ms\n",
            "image 108/137 /content/MV_Train_Data-2/test/images/Energy-05471_jpg.rf.f66379640afe772c9da15fd14196bfdd.jpg: 640x640 1 EnergyPlus_Large, 3 EnergyPlus_Regs, 7.5ms\n",
            "image 109/137 /content/MV_Train_Data-2/test/images/Energy-05581_jpg.rf.09e4c146dc0aa077cee45054c97c490b.jpg: 640x640 3 EnergyPlus_Regs, 7.5ms\n",
            "image 110/137 /content/MV_Train_Data-2/test/images/Energy-05606_jpg.rf.28b5aa257fb0fc74db9dae5880a937a3.jpg: 640x640 3 EnergyPlus_Regs, 7.5ms\n",
            "image 111/137 /content/MV_Train_Data-2/test/images/Energy-05706_jpg.rf.b24d09f7d7015dcf4caf5cc6de8a467d.jpg: 640x640 1 EnergyPlus_Large, 3 EnergyPlus_Regs, 7.9ms\n",
            "image 112/137 /content/MV_Train_Data-2/test/images/Energy-05761_jpg.rf.faae701bf2ee5137c7c8ff87c3751750.jpg: 640x640 2 EnergyPlus_Larges, 3 EnergyPlus_Regs, 7.5ms\n",
            "image 113/137 /content/MV_Train_Data-2/test/images/Energy-05766_jpg.rf.ad8a50969b2b68c56661833a31665941.jpg: 640x640 2 EnergyPlus_Larges, 3 EnergyPlus_Regs, 9.6ms\n",
            "image 114/137 /content/MV_Train_Data-2/test/images/Energy-05801_jpg.rf.b2922efe4510b9e5ca4d41895b8d1937.jpg: 640x640 2 EnergyPlus_Larges, 2 EnergyPlus_Regs, 7.5ms\n",
            "image 115/137 /content/MV_Train_Data-2/test/images/Energy-05831_jpg.rf.f2779e6a4174ebc6e548ca1b0a99267a.jpg: 640x640 2 EnergyPlus_Larges, 1 EnergyPlus_Reg, 7.5ms\n",
            "image 116/137 /content/MV_Train_Data-2/test/images/Energy-05881_jpg.rf.ea02909ce8bd618f40fb9c0cf997c7e8.jpg: 640x640 3 EnergyPlus_Larges, 1 EnergyPlus_Reg, 8.2ms\n",
            "image 117/137 /content/MV_Train_Data-2/test/images/Energy-05941_jpg.rf.46a5b5b78f412a1279ec629fc81e3760.jpg: 640x640 1 EnergyPlus_Large, 2 EnergyPlus_Regs, 9.5ms\n",
            "image 118/137 /content/MV_Train_Data-2/test/images/Energy-06031_jpg.rf.c10190abd69d4f485d293d2499f4fc4b.jpg: 640x640 3 EnergyPlus_Regs, 8.0ms\n",
            "image 119/137 /content/MV_Train_Data-2/test/images/Energy-06041_jpg.rf.6c54ddf1595c919cb103c38854d7b8b3.jpg: 640x640 3 EnergyPlus_Regs, 7.5ms\n",
            "image 120/137 /content/MV_Train_Data-2/test/images/Energy-06066_jpg.rf.728617d97d055ca992407c201f9a05ac.jpg: 640x640 3 EnergyPlus_Regs, 7.5ms\n",
            "image 121/137 /content/MV_Train_Data-2/test/images/Energy-06091_jpg.rf.150c6b5d8e29e7cce05eca472d73b63c.jpg: 640x640 3 EnergyPlus_Regs, 7.5ms\n",
            "image 122/137 /content/MV_Train_Data-2/test/images/Energy-06241_jpg.rf.d812ff259873fd941db24ead047052fc.jpg: 640x640 3 EnergyPlus_Regs, 7.5ms\n",
            "image 123/137 /content/MV_Train_Data-2/test/images/Energy-06341_jpg.rf.d4f07332ddc75adc59e3e0675b3f1b58.jpg: 640x640 1 EnergyPlus_Large, 1 EnergyPlus_Reg, 7.5ms\n",
            "image 124/137 /content/MV_Train_Data-2/test/images/Energy-06346_jpg.rf.2bd746e4abb6f3e67aeb84d968ec32b1.jpg: 640x640 1 EnergyPlus_Large, 1 EnergyPlus_Reg, 8.4ms\n",
            "image 125/137 /content/MV_Train_Data-2/test/images/Energy-06356_jpg.rf.7640412ca3c4286f19e45ffd0dd6dffa.jpg: 640x640 1 EnergyPlus_Large, 1 EnergyPlus_Reg, 7.7ms\n",
            "image 126/137 /content/MV_Train_Data-2/test/images/Energy-06391_jpg.rf.b6bdf3449d16172ddb0f6c5031895385.jpg: 640x640 2 EnergyPlus_Regs, 7.6ms\n",
            "image 127/137 /content/MV_Train_Data-2/test/images/Energy-06451_jpg.rf.0a3890a4d350a11fd306a8807379379a.jpg: 640x640 3 EnergyPlus_Regs, 7.5ms\n",
            "image 128/137 /content/MV_Train_Data-2/test/images/Energy-06521_jpg.rf.7f6a8bee74f1f934fdb5c3260db3f318.jpg: 640x640 4 EnergyPlus_Regs, 7.5ms\n",
            "image 129/137 /content/MV_Train_Data-2/test/images/Energy-06526_jpg.rf.31e93851d46529f46bfb13b42c6393a4.jpg: 640x640 4 EnergyPlus_Regs, 9.3ms\n",
            "image 130/137 /content/MV_Train_Data-2/test/images/Energy-06576_jpg.rf.bfa90fafe52ce35c95af71664febd77b.jpg: 640x640 4 EnergyPlus_Regs, 7.6ms\n",
            "image 131/137 /content/MV_Train_Data-2/test/images/Energy-06636_jpg.rf.6069fd6c75b0973f0811078401f075fe.jpg: 640x640 1 EnergyPlus_Large, 4 EnergyPlus_Regs, 11.8ms\n",
            "image 132/137 /content/MV_Train_Data-2/test/images/Energy-06666_jpg.rf.529dbdb6d93ea2fe30e3a31e64d5ece2.jpg: 640x640 2 EnergyPlus_Larges, 3 EnergyPlus_Regs, 9.4ms\n",
            "image 133/137 /content/MV_Train_Data-2/test/images/Energy-06691_jpg.rf.6795b510c829b41f279a3482e9869170.jpg: 640x640 2 EnergyPlus_Larges, 2 EnergyPlus_Regs, 7.6ms\n",
            "image 134/137 /content/MV_Train_Data-2/test/images/Energy-06721_jpg.rf.600a16ee58d1d89f89351701c6b33512.jpg: 640x640 2 EnergyPlus_Larges, 1 EnergyPlus_Reg, 10.7ms\n",
            "image 135/137 /content/MV_Train_Data-2/test/images/Energy-06746_jpg.rf.d83298d6f7839e4bd69781180f99ae1a.jpg: 640x640 2 EnergyPlus_Larges, 2 EnergyPlus_Regs, 10.3ms\n",
            "image 136/137 /content/MV_Train_Data-2/test/images/Energy-06751_jpg.rf.330606b3a0e47aa1a441265872927d8a.jpg: 640x640 3 EnergyPlus_Larges, 2 EnergyPlus_Regs, 10.3ms\n",
            "image 137/137 /content/MV_Train_Data-2/test/images/Energy-06876_jpg.rf.86fa8ac4b4375fbe62a460e5acd2ed3d.jpg: 640x640 1 EnergyPlus_Large, 2 EnergyPlus_Regs, 10.9ms\n",
            "Speed: 1.7ms preprocess, 9.1ms inference, 5.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1mruns/detect/predict\u001b[0m\n",
            "💡 Learn more at https://docs.ultralytics.com/modes/predict\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8KdBkOflo2xY",
        "outputId": "134316d9-e3d7-424a-a0c0-639499f9ef7a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "yolox.__version__: 0.1.0\n"
          ]
        }
      ],
      "source": [
        "%cd {HOME}\n",
        "!git clone https://github.com/ifzhang/ByteTrack.git\n",
        "%cd {HOME}/ByteTrack\n",
        "\n",
        "# workaround related to https://github.com/roboflow/notebooks/issues/80\n",
        "!sed -i 's/onnx==1.8.1/onnx==1.9.0/g' requirements.txt\n",
        "\n",
        "!pip3 install -q -r requirements.txt\n",
        "!python3 setup.py -q develop\n",
        "!pip install -q cython_bbox\n",
        "!pip install -q onemetric\n",
        "# workaround related to https://github.com/roboflow/notebooks/issues/112 and https://github.com/roboflow/notebooks/issues/106\n",
        "!pip install -q loguru lap thop\n",
        "\n",
        "from IPython import display\n",
        "display.clear_output()\n",
        "\n",
        "\n",
        "import sys\n",
        "sys.path.append(f\"{HOME}/ByteTrack\")\n",
        "\n",
        "\n",
        "import yolox\n",
        "print(\"yolox.__version__:\", yolox.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "rwg-lY49o7Sf"
      },
      "outputs": [],
      "source": [
        "from yolox.tracker.byte_tracker import BYTETracker, STrack\n",
        "from onemetric.cv.utils.iou import box_iou_batch\n",
        "from dataclasses import dataclass\n",
        "\n",
        "\n",
        "@dataclass(frozen=True)\n",
        "class BYTETrackerArgs:\n",
        "    track_thresh: float = 0.25\n",
        "    track_buffer: int = 30\n",
        "    match_thresh: float = 0.8\n",
        "    aspect_ratio_thresh: float = 3.0\n",
        "    min_box_area: float = 1.0\n",
        "    mot20: bool = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d60yX_PFQ9A2",
        "outputId": "7cd11928-38fd-4ea9-9799-6b6a963b797f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "supervision.__version__: 0.1.0\n"
          ]
        }
      ],
      "source": [
        "!pip install supervision==0.1.0\n",
        "from IPython import display\n",
        "display.clear_output()\n",
        "import supervision\n",
        "print(\"supervision.__version__:\", supervision.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "7YDohOpMTWH5"
      },
      "outputs": [],
      "source": [
        "from supervision.draw.color import ColorPalette\n",
        "from supervision.geometry.dataclasses import Point\n",
        "from supervision.video.dataclasses import VideoInfo\n",
        "from supervision.video.source import get_video_frames_generator\n",
        "from supervision.video.sink import VideoSink\n",
        "from supervision.notebook.utils import show_frame_in_notebook\n",
        "from supervision.tools.detections import Detections, BoxAnnotator\n",
        "from supervision.tools.line_counter import LineCounter, LineCounterAnnotator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mPdB-v_hWxBy"
      },
      "source": [
        "## Tracking utils\n",
        "\n",
        "Unfortunately, we have to manually match the bounding boxes coming from our model with those created by the tracker."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "SE0G6LvFAXlk"
      },
      "outputs": [],
      "source": [
        "from typing import List\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# converts Detections into format that can be consumed by match_detections_with_tracks function\n",
        "def detections2boxes(detections: Detections) -> np.ndarray:\n",
        "    return np.hstack((\n",
        "        detections.xyxy,\n",
        "        detections.confidence[:, np.newaxis]\n",
        "    ))\n",
        "\n",
        "\n",
        "# converts List[STrack] into format that can be consumed by match_detections_with_tracks function\n",
        "def tracks2boxes(tracks: List[STrack]) -> np.ndarray:\n",
        "    return np.array([\n",
        "        track.tlbr\n",
        "        for track\n",
        "        in tracks\n",
        "    ], dtype=float)\n",
        "\n",
        "\n",
        "# matches our bounding boxes with predictions\n",
        "def match_detections_with_tracks(\n",
        "    detections: Detections,\n",
        "    tracks: List[STrack]\n",
        ") -> Detections:\n",
        "    if not np.any(detections.xyxy) or len(tracks) == 0:\n",
        "        return np.empty((0,))\n",
        "\n",
        "    tracks_boxes = tracks2boxes(tracks=tracks)\n",
        "    iou = box_iou_batch(tracks_boxes, detections.xyxy)\n",
        "    track2detection = np.argmax(iou, axis=1)\n",
        "\n",
        "    tracker_ids = [None] * len(detections)\n",
        "\n",
        "    for tracker_index, detection_index in enumerate(track2detection):\n",
        "        if iou[tracker_index, detection_index] != 0:\n",
        "            tracker_ids[detection_index] = tracks[tracker_index].track_id\n",
        "\n",
        "    return tracker_ids"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/facebookresearch/segment-anything.git\n",
        "!pip install opencv-python matplotlib"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iLV6OgBVNg6s",
        "outputId": "181b9ad4-21b4-4ff1-d4a2-3a651df06ec8"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/facebookresearch/segment-anything.git\n",
            "  Cloning https://github.com/facebookresearch/segment-anything.git to /tmp/pip-req-build-kxrxh937\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/facebookresearch/segment-anything.git /tmp/pip-req-build-kxrxh937\n",
            "  Resolved https://github.com/facebookresearch/segment-anything.git to commit dca509fe793f601edb92606367a655c15ac00fdf\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: segment_anything\n",
            "  Building wheel for segment_anything (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for segment_anything: filename=segment_anything-1.0-py3-none-any.whl size=36592 sha256=589a811ce6dfef2255d97932347842ff219100a8734723e29ab6486fdbf3efed\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-w5xmfhmu/wheels/10/cf/59/9ccb2f0a1bcc81d4fbd0e501680b5d088d690c6cfbc02dc99d\n",
            "Successfully built segment_anything\n",
            "Installing collected packages: segment_anything\n",
            "Successfully installed segment_anything-1.0\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.8.0)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python) (1.26.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.55.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (11.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "from ultralytics import YOLO\n",
        "from segment_anything import SamAutomaticMaskGenerator, sam_model_registry\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "yolo_model = YOLO('/content/runs/detect/train/weights/best.pt')\n",
        "sam_checkpoint = \"/content/drive/MyDrive/sam_vit_h_4b8939.pth\"\n",
        "sam_model = sam_model_registry[\"vit_h\"](checkpoint=sam_checkpoint)\n",
        "sam_model.to(device)\n",
        "mask_generator = SamAutomaticMaskGenerator(sam_model)\n",
        "\n",
        "\n",
        "SOURCE_VIDEO_PATH = '/content/17397133-preview.mp4'\n",
        "TARGET_VIDEO_PATH = '/content/hybrid-output.mp4'\n",
        "\n",
        "# Open video capture\n",
        "cap = cv2.VideoCapture(SOURCE_VIDEO_PATH)\n",
        "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "frame_rate = int(cap.get(cv2.CAP_PROP_FPS))\n",
        "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
        "out = cv2.VideoWriter(TARGET_VIDEO_PATH, fourcc, frame_rate, (frame_width, frame_height))\n",
        "\n",
        "frame_count = 0\n",
        "total_object_count = 0\n",
        "frame_skip = 5\n",
        "while cap.isOpened():\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "    if frame_count % frame_skip != 0:\n",
        "        frame_count += 1\n",
        "        continue\n",
        "    frame_resized = cv2.resize(frame, (frame_width // 2, frame_height // 2))\n",
        "    frame_rgb = cv2.cvtColor(frame_resized, cv2.COLOR_BGR2RGB)\n",
        "    results = yolo_model(frame)\n",
        "    detections = results[0].boxes.xyxy.cpu().numpy()\n",
        "    object_count = 0\n",
        "\n",
        "    for bbox in detections:\n",
        "        x1, y1, x2, y2 = map(int, bbox)\n",
        "        x1 = max(0, x1)\n",
        "        y1 = max(0, y1)\n",
        "        x2 = min(frame_rgb.shape[1], x2)\n",
        "        y2 = min(frame_rgb.shape[0], y2)\n",
        "        if x2 <= x1 or y2 <= y1:\n",
        "            continue\n",
        "        cropped_frame = frame_rgb[y1:y2, x1:x2]\n",
        "\n",
        "        masks = mask_generator.generate(cropped_frame)\n",
        "        for mask in masks:\n",
        "            mask_image = mask[\"segmentation\"].astype(np.uint8)\n",
        "            if np.any(mask_image > 0):\n",
        "                object_count += 1\n",
        "                frame[y1:y2, x1:x2][mask_image > 0] = (0, 255, 0)\n",
        "    total_object_count += object_count\n",
        "    cv2.putText(frame, f\"Total Objects: {total_object_count}\", (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 255), 2)\n",
        "    out.write(frame)\n",
        "    print(f\"Processed frame {frame_count + 1}, Frame Objects: {object_count}, Total Objects: {total_object_count}\")\n",
        "    frame_count += 1\n",
        "\n",
        "cap.release()\n",
        "out.release()\n",
        "cv2.destroyAllWindows()\n",
        "\n",
        "print(f\"Final Total Objects Counted: {total_object_count}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5tFeL0wHWEw3",
        "outputId": "5cca9621-3770-4ab3-9141-03687e4eea8a"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 EnergyPlus_Large, 11.5ms\n",
            "Speed: 1.9ms preprocess, 11.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 1, Frame Objects: 0, Total Objects: 0\n",
            "\n",
            "0: 384x640 2 EnergyPlus_Larges, 10.7ms\n",
            "Speed: 2.5ms preprocess, 10.7ms inference, 84.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 6, Frame Objects: 14, Total Objects: 14\n",
            "\n",
            "0: 384x640 1 EnergyPlus_Large, 9.5ms\n",
            "Speed: 2.3ms preprocess, 9.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 11, Frame Objects: 13, Total Objects: 27\n",
            "\n",
            "0: 384x640 (no detections), 7.3ms\n",
            "Speed: 2.4ms preprocess, 7.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 16, Frame Objects: 0, Total Objects: 27\n",
            "\n",
            "0: 384x640 (no detections), 6.6ms\n",
            "Speed: 1.6ms preprocess, 6.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 21, Frame Objects: 0, Total Objects: 27\n",
            "\n",
            "0: 384x640 (no detections), 7.0ms\n",
            "Speed: 2.2ms preprocess, 7.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 26, Frame Objects: 0, Total Objects: 27\n",
            "\n",
            "0: 384x640 (no detections), 6.2ms\n",
            "Speed: 2.8ms preprocess, 6.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 31, Frame Objects: 0, Total Objects: 27\n",
            "\n",
            "0: 384x640 (no detections), 9.4ms\n",
            "Speed: 3.2ms preprocess, 9.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 36, Frame Objects: 0, Total Objects: 27\n",
            "\n",
            "0: 384x640 (no detections), 8.9ms\n",
            "Speed: 2.2ms preprocess, 8.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 41, Frame Objects: 0, Total Objects: 27\n",
            "\n",
            "0: 384x640 (no detections), 8.8ms\n",
            "Speed: 2.7ms preprocess, 8.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 46, Frame Objects: 0, Total Objects: 27\n",
            "\n",
            "0: 384x640 1 EnergyPlus_Large, 9.0ms\n",
            "Speed: 2.3ms preprocess, 9.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 51, Frame Objects: 0, Total Objects: 27\n",
            "\n",
            "0: 384x640 1 EnergyPlus_Large, 10.7ms\n",
            "Speed: 2.9ms preprocess, 10.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 56, Frame Objects: 0, Total Objects: 27\n",
            "\n",
            "0: 384x640 1 EnergyPlus_Large, 6.9ms\n",
            "Speed: 1.6ms preprocess, 6.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 61, Frame Objects: 0, Total Objects: 27\n",
            "\n",
            "0: 384x640 1 EnergyPlus_Large, 6.4ms\n",
            "Speed: 2.9ms preprocess, 6.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 66, Frame Objects: 0, Total Objects: 27\n",
            "\n",
            "0: 384x640 1 EnergyPlus_Large, 13.9ms\n",
            "Speed: 2.3ms preprocess, 13.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 71, Frame Objects: 0, Total Objects: 27\n",
            "\n",
            "0: 384x640 3 EnergyPlus_Larges, 6.7ms\n",
            "Speed: 3.0ms preprocess, 6.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 76, Frame Objects: 0, Total Objects: 27\n",
            "\n",
            "0: 384x640 1 EnergyPlus_Large, 8.5ms\n",
            "Speed: 2.2ms preprocess, 8.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 81, Frame Objects: 0, Total Objects: 27\n",
            "\n",
            "0: 384x640 1 EnergyPlus_Large, 6.3ms\n",
            "Speed: 2.0ms preprocess, 6.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 86, Frame Objects: 0, Total Objects: 27\n",
            "\n",
            "0: 384x640 1 EnergyPlus_Large, 6.7ms\n",
            "Speed: 1.9ms preprocess, 6.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 91, Frame Objects: 0, Total Objects: 27\n",
            "\n",
            "0: 384x640 1 EnergyPlus_Large, 8.0ms\n",
            "Speed: 2.9ms preprocess, 8.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 96, Frame Objects: 0, Total Objects: 27\n",
            "\n",
            "0: 384x640 2 EnergyPlus_Larges, 9.5ms\n",
            "Speed: 2.4ms preprocess, 9.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 101, Frame Objects: 0, Total Objects: 27\n",
            "\n",
            "0: 384x640 2 EnergyPlus_Larges, 6.8ms\n",
            "Speed: 2.4ms preprocess, 6.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 106, Frame Objects: 0, Total Objects: 27\n",
            "\n",
            "0: 384x640 2 EnergyPlus_Larges, 7.5ms\n",
            "Speed: 3.7ms preprocess, 7.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 111, Frame Objects: 0, Total Objects: 27\n",
            "\n",
            "0: 384x640 2 EnergyPlus_Larges, 7.0ms\n",
            "Speed: 2.1ms preprocess, 7.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 116, Frame Objects: 0, Total Objects: 27\n",
            "\n",
            "0: 384x640 2 EnergyPlus_Larges, 6.9ms\n",
            "Speed: 3.0ms preprocess, 6.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 121, Frame Objects: 0, Total Objects: 27\n",
            "\n",
            "0: 384x640 1 EnergyPlus_Large, 6.7ms\n",
            "Speed: 2.8ms preprocess, 6.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 126, Frame Objects: 0, Total Objects: 27\n",
            "\n",
            "0: 384x640 1 EnergyPlus_Large, 6.3ms\n",
            "Speed: 2.7ms preprocess, 6.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 131, Frame Objects: 0, Total Objects: 27\n",
            "\n",
            "0: 384x640 1 EnergyPlus_Large, 6.3ms\n",
            "Speed: 4.0ms preprocess, 6.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 136, Frame Objects: 0, Total Objects: 27\n",
            "\n",
            "0: 384x640 1 EnergyPlus_Large, 6.2ms\n",
            "Speed: 2.9ms preprocess, 6.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 141, Frame Objects: 0, Total Objects: 27\n",
            "\n",
            "0: 384x640 2 EnergyPlus_Larges, 6.7ms\n",
            "Speed: 3.3ms preprocess, 6.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 146, Frame Objects: 0, Total Objects: 27\n",
            "\n",
            "0: 384x640 (no detections), 9.4ms\n",
            "Speed: 2.3ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 151, Frame Objects: 0, Total Objects: 27\n",
            "\n",
            "0: 384x640 1 EnergyPlus_Large, 6.9ms\n",
            "Speed: 2.1ms preprocess, 6.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 156, Frame Objects: 0, Total Objects: 27\n",
            "\n",
            "0: 384x640 2 EnergyPlus_Larges, 7.0ms\n",
            "Speed: 2.1ms preprocess, 7.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 161, Frame Objects: 0, Total Objects: 27\n",
            "\n",
            "0: 384x640 4 EnergyPlus_Larges, 6.7ms\n",
            "Speed: 2.1ms preprocess, 6.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 166, Frame Objects: 0, Total Objects: 27\n",
            "\n",
            "0: 384x640 2 EnergyPlus_Larges, 6.4ms\n",
            "Speed: 2.2ms preprocess, 6.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 171, Frame Objects: 0, Total Objects: 27\n",
            "\n",
            "0: 384x640 1 EnergyPlus_Large, 6.9ms\n",
            "Speed: 2.5ms preprocess, 6.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 176, Frame Objects: 0, Total Objects: 27\n",
            "\n",
            "0: 384x640 1 EnergyPlus_Large, 6.9ms\n",
            "Speed: 2.7ms preprocess, 6.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 181, Frame Objects: 0, Total Objects: 27\n",
            "\n",
            "0: 384x640 1 EnergyPlus_Large, 7.7ms\n",
            "Speed: 2.5ms preprocess, 7.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 186, Frame Objects: 0, Total Objects: 27\n",
            "\n",
            "0: 384x640 1 EnergyPlus_Large, 6.3ms\n",
            "Speed: 2.0ms preprocess, 6.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 191, Frame Objects: 0, Total Objects: 27\n",
            "\n",
            "0: 384x640 1 EnergyPlus_Large, 6.6ms\n",
            "Speed: 2.1ms preprocess, 6.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 196, Frame Objects: 0, Total Objects: 27\n",
            "\n",
            "0: 384x640 2 EnergyPlus_Larges, 6.3ms\n",
            "Speed: 1.8ms preprocess, 6.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 201, Frame Objects: 0, Total Objects: 27\n",
            "\n",
            "0: 384x640 2 EnergyPlus_Larges, 6.5ms\n",
            "Speed: 2.6ms preprocess, 6.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 206, Frame Objects: 0, Total Objects: 27\n",
            "\n",
            "0: 384x640 2 EnergyPlus_Larges, 6.1ms\n",
            "Speed: 2.7ms preprocess, 6.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 211, Frame Objects: 0, Total Objects: 27\n",
            "\n",
            "0: 384x640 1 EnergyPlus_Large, 7.3ms\n",
            "Speed: 2.3ms preprocess, 7.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 216, Frame Objects: 0, Total Objects: 27\n",
            "\n",
            "0: 384x640 1 EnergyPlus_Large, 6.7ms\n",
            "Speed: 2.8ms preprocess, 6.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 221, Frame Objects: 0, Total Objects: 27\n",
            "\n",
            "0: 384x640 1 EnergyPlus_Large, 6.7ms\n",
            "Speed: 2.9ms preprocess, 6.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 226, Frame Objects: 0, Total Objects: 27\n",
            "\n",
            "0: 384x640 1 EnergyPlus_Large, 9.1ms\n",
            "Speed: 3.6ms preprocess, 9.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 231, Frame Objects: 0, Total Objects: 27\n",
            "\n",
            "0: 384x640 1 EnergyPlus_Large, 9.5ms\n",
            "Speed: 1.6ms preprocess, 9.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 236, Frame Objects: 0, Total Objects: 27\n",
            "\n",
            "0: 384x640 1 EnergyPlus_Large, 9.4ms\n",
            "Speed: 3.6ms preprocess, 9.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 241, Frame Objects: 0, Total Objects: 27\n",
            "\n",
            "0: 384x640 1 EnergyPlus_Large, 9.1ms\n",
            "Speed: 2.6ms preprocess, 9.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 246, Frame Objects: 0, Total Objects: 27\n",
            "\n",
            "0: 384x640 2 EnergyPlus_Larges, 9.8ms\n",
            "Speed: 3.6ms preprocess, 9.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 251, Frame Objects: 0, Total Objects: 27\n",
            "\n",
            "0: 384x640 2 EnergyPlus_Larges, 9.3ms\n",
            "Speed: 2.3ms preprocess, 9.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 256, Frame Objects: 0, Total Objects: 27\n",
            "\n",
            "0: 384x640 1 EnergyPlus_Large, 9.4ms\n",
            "Speed: 2.8ms preprocess, 9.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 261, Frame Objects: 0, Total Objects: 27\n",
            "\n",
            "0: 384x640 1 EnergyPlus_Large, 13.0ms\n",
            "Speed: 2.4ms preprocess, 13.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 266, Frame Objects: 0, Total Objects: 27\n",
            "\n",
            "0: 384x640 1 EnergyPlus_Large, 10.2ms\n",
            "Speed: 2.5ms preprocess, 10.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 271, Frame Objects: 0, Total Objects: 27\n",
            "\n",
            "0: 384x640 2 EnergyPlus_Larges, 11.6ms\n",
            "Speed: 2.0ms preprocess, 11.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 276, Frame Objects: 0, Total Objects: 27\n",
            "\n",
            "0: 384x640 1 EnergyPlus_Large, 10.0ms\n",
            "Speed: 2.9ms preprocess, 10.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 281, Frame Objects: 0, Total Objects: 27\n",
            "\n",
            "0: 384x640 1 EnergyPlus_Large, 10.1ms\n",
            "Speed: 2.9ms preprocess, 10.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 286, Frame Objects: 0, Total Objects: 27\n",
            "\n",
            "0: 384x640 2 EnergyPlus_Larges, 10.2ms\n",
            "Speed: 2.8ms preprocess, 10.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 291, Frame Objects: 0, Total Objects: 27\n",
            "\n",
            "0: 384x640 1 EnergyPlus_Large, 10.1ms\n",
            "Speed: 2.4ms preprocess, 10.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 296, Frame Objects: 0, Total Objects: 27\n",
            "\n",
            "0: 384x640 3 EnergyPlus_Larges, 10.4ms\n",
            "Speed: 3.2ms preprocess, 10.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 301, Frame Objects: 0, Total Objects: 27\n",
            "\n",
            "0: 384x640 2 EnergyPlus_Larges, 9.8ms\n",
            "Speed: 2.9ms preprocess, 9.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 306, Frame Objects: 0, Total Objects: 27\n",
            "\n",
            "0: 384x640 3 EnergyPlus_Larges, 9.5ms\n",
            "Speed: 3.5ms preprocess, 9.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 311, Frame Objects: 0, Total Objects: 27\n",
            "\n",
            "0: 384x640 3 EnergyPlus_Larges, 9.5ms\n",
            "Speed: 3.6ms preprocess, 9.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 316, Frame Objects: 0, Total Objects: 27\n",
            "\n",
            "0: 384x640 2 EnergyPlus_Larges, 9.3ms\n",
            "Speed: 3.7ms preprocess, 9.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 321, Frame Objects: 0, Total Objects: 27\n",
            "\n",
            "0: 384x640 1 EnergyPlus_Large, 9.5ms\n",
            "Speed: 2.0ms preprocess, 9.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 326, Frame Objects: 0, Total Objects: 27\n",
            "\n",
            "0: 384x640 2 EnergyPlus_Larges, 10.4ms\n",
            "Speed: 2.2ms preprocess, 10.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 331, Frame Objects: 0, Total Objects: 27\n",
            "\n",
            "0: 384x640 2 EnergyPlus_Larges, 9.3ms\n",
            "Speed: 3.0ms preprocess, 9.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 336, Frame Objects: 0, Total Objects: 27\n",
            "\n",
            "0: 384x640 3 EnergyPlus_Larges, 11.6ms\n",
            "Speed: 2.8ms preprocess, 11.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 341, Frame Objects: 0, Total Objects: 27\n",
            "\n",
            "0: 384x640 1 EnergyPlus_Large, 9.6ms\n",
            "Speed: 1.9ms preprocess, 9.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 346, Frame Objects: 0, Total Objects: 27\n",
            "\n",
            "0: 384x640 1 EnergyPlus_Large, 8.4ms\n",
            "Speed: 3.5ms preprocess, 8.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 351, Frame Objects: 0, Total Objects: 27\n",
            "\n",
            "0: 384x640 1 EnergyPlus_Large, 9.1ms\n",
            "Speed: 3.9ms preprocess, 9.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 356, Frame Objects: 0, Total Objects: 27\n",
            "\n",
            "0: 384x640 1 EnergyPlus_Large, 9.3ms\n",
            "Speed: 2.8ms preprocess, 9.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 361, Frame Objects: 0, Total Objects: 27\n",
            "\n",
            "0: 384x640 2 EnergyPlus_Larges, 9.1ms\n",
            "Speed: 2.4ms preprocess, 9.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 366, Frame Objects: 0, Total Objects: 27\n",
            "\n",
            "0: 384x640 1 EnergyPlus_Large, 8.5ms\n",
            "Speed: 2.5ms preprocess, 8.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 371, Frame Objects: 0, Total Objects: 27\n",
            "\n",
            "0: 384x640 2 EnergyPlus_Larges, 9.8ms\n",
            "Speed: 2.9ms preprocess, 9.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 376, Frame Objects: 0, Total Objects: 27\n",
            "\n",
            "0: 384x640 1 EnergyPlus_Large, 9.7ms\n",
            "Speed: 3.2ms preprocess, 9.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 381, Frame Objects: 0, Total Objects: 27\n",
            "\n",
            "0: 384x640 2 EnergyPlus_Larges, 10.3ms\n",
            "Speed: 2.5ms preprocess, 10.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 386, Frame Objects: 13, Total Objects: 40\n",
            "\n",
            "0: 384x640 2 EnergyPlus_Larges, 12.4ms\n",
            "Speed: 2.4ms preprocess, 12.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 391, Frame Objects: 10, Total Objects: 50\n",
            "\n",
            "0: 384x640 1 EnergyPlus_Large, 9.1ms\n",
            "Speed: 2.0ms preprocess, 9.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 396, Frame Objects: 0, Total Objects: 50\n",
            "\n",
            "0: 384x640 1 EnergyPlus_Large, 6.9ms\n",
            "Speed: 2.1ms preprocess, 6.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 401, Frame Objects: 0, Total Objects: 50\n",
            "\n",
            "0: 384x640 (no detections), 8.4ms\n",
            "Speed: 2.2ms preprocess, 8.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 406, Frame Objects: 0, Total Objects: 50\n",
            "\n",
            "0: 384x640 2 EnergyPlus_Larges, 9.1ms\n",
            "Speed: 2.2ms preprocess, 9.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 411, Frame Objects: 0, Total Objects: 50\n",
            "\n",
            "0: 384x640 1 EnergyPlus_Large, 6.5ms\n",
            "Speed: 2.2ms preprocess, 6.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 416, Frame Objects: 0, Total Objects: 50\n",
            "\n",
            "0: 384x640 (no detections), 6.7ms\n",
            "Speed: 2.6ms preprocess, 6.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 421, Frame Objects: 0, Total Objects: 50\n",
            "\n",
            "0: 384x640 (no detections), 7.1ms\n",
            "Speed: 2.3ms preprocess, 7.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 426, Frame Objects: 0, Total Objects: 50\n",
            "\n",
            "0: 384x640 (no detections), 6.5ms\n",
            "Speed: 2.9ms preprocess, 6.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 431, Frame Objects: 0, Total Objects: 50\n",
            "\n",
            "0: 384x640 (no detections), 6.3ms\n",
            "Speed: 2.1ms preprocess, 6.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 436, Frame Objects: 0, Total Objects: 50\n",
            "\n",
            "0: 384x640 (no detections), 6.4ms\n",
            "Speed: 2.9ms preprocess, 6.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 441, Frame Objects: 0, Total Objects: 50\n",
            "\n",
            "0: 384x640 (no detections), 7.3ms\n",
            "Speed: 2.6ms preprocess, 7.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 446, Frame Objects: 0, Total Objects: 50\n",
            "\n",
            "0: 384x640 (no detections), 6.4ms\n",
            "Speed: 2.1ms preprocess, 6.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 451, Frame Objects: 0, Total Objects: 50\n",
            "\n",
            "0: 384x640 1 EnergyPlus_Large, 8.1ms\n",
            "Speed: 2.2ms preprocess, 8.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 456, Frame Objects: 0, Total Objects: 50\n",
            "\n",
            "0: 384x640 2 EnergyPlus_Larges, 6.5ms\n",
            "Speed: 2.8ms preprocess, 6.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 461, Frame Objects: 0, Total Objects: 50\n",
            "\n",
            "0: 384x640 2 EnergyPlus_Larges, 6.6ms\n",
            "Speed: 2.5ms preprocess, 6.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 466, Frame Objects: 0, Total Objects: 50\n",
            "\n",
            "0: 384x640 3 EnergyPlus_Larges, 6.3ms\n",
            "Speed: 2.8ms preprocess, 6.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 471, Frame Objects: 0, Total Objects: 50\n",
            "\n",
            "0: 384x640 3 EnergyPlus_Larges, 6.6ms\n",
            "Speed: 2.1ms preprocess, 6.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 476, Frame Objects: 0, Total Objects: 50\n",
            "\n",
            "0: 384x640 3 EnergyPlus_Larges, 6.7ms\n",
            "Speed: 2.7ms preprocess, 6.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 481, Frame Objects: 0, Total Objects: 50\n",
            "\n",
            "0: 384x640 1 EnergyPlus_Large, 6.8ms\n",
            "Speed: 2.3ms preprocess, 6.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 486, Frame Objects: 0, Total Objects: 50\n",
            "\n",
            "0: 384x640 1 EnergyPlus_Large, 6.6ms\n",
            "Speed: 2.1ms preprocess, 6.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 491, Frame Objects: 0, Total Objects: 50\n",
            "\n",
            "0: 384x640 1 EnergyPlus_Large, 6.9ms\n",
            "Speed: 2.2ms preprocess, 6.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 496, Frame Objects: 0, Total Objects: 50\n",
            "\n",
            "0: 384x640 2 EnergyPlus_Larges, 6.9ms\n",
            "Speed: 2.2ms preprocess, 6.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 501, Frame Objects: 0, Total Objects: 50\n",
            "\n",
            "0: 384x640 2 EnergyPlus_Larges, 13.9ms\n",
            "Speed: 2.6ms preprocess, 13.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 506, Frame Objects: 0, Total Objects: 50\n",
            "\n",
            "0: 384x640 2 EnergyPlus_Larges, 6.6ms\n",
            "Speed: 2.3ms preprocess, 6.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 511, Frame Objects: 0, Total Objects: 50\n",
            "\n",
            "0: 384x640 1 EnergyPlus_Large, 6.6ms\n",
            "Speed: 2.2ms preprocess, 6.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 516, Frame Objects: 0, Total Objects: 50\n",
            "\n",
            "0: 384x640 1 EnergyPlus_Large, 6.4ms\n",
            "Speed: 2.0ms preprocess, 6.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 521, Frame Objects: 0, Total Objects: 50\n",
            "\n",
            "0: 384x640 1 EnergyPlus_Large, 7.1ms\n",
            "Speed: 2.0ms preprocess, 7.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 526, Frame Objects: 0, Total Objects: 50\n",
            "\n",
            "0: 384x640 1 EnergyPlus_Large, 6.6ms\n",
            "Speed: 3.0ms preprocess, 6.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 531, Frame Objects: 0, Total Objects: 50\n",
            "\n",
            "0: 384x640 2 EnergyPlus_Larges, 11.5ms\n",
            "Speed: 2.5ms preprocess, 11.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 536, Frame Objects: 0, Total Objects: 50\n",
            "\n",
            "0: 384x640 2 EnergyPlus_Larges, 6.6ms\n",
            "Speed: 2.2ms preprocess, 6.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 541, Frame Objects: 0, Total Objects: 50\n",
            "\n",
            "0: 384x640 1 EnergyPlus_Large, 7.2ms\n",
            "Speed: 2.2ms preprocess, 7.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 546, Frame Objects: 0, Total Objects: 50\n",
            "\n",
            "0: 384x640 3 EnergyPlus_Larges, 14.5ms\n",
            "Speed: 2.6ms preprocess, 14.5ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 551, Frame Objects: 0, Total Objects: 50\n",
            "\n",
            "0: 384x640 3 EnergyPlus_Larges, 10.4ms\n",
            "Speed: 2.3ms preprocess, 10.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 556, Frame Objects: 0, Total Objects: 50\n",
            "\n",
            "0: 384x640 1 EnergyPlus_Large, 9.8ms\n",
            "Speed: 2.9ms preprocess, 9.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 561, Frame Objects: 0, Total Objects: 50\n",
            "\n",
            "0: 384x640 1 EnergyPlus_Large, 10.1ms\n",
            "Speed: 2.6ms preprocess, 10.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 566, Frame Objects: 0, Total Objects: 50\n",
            "\n",
            "0: 384x640 2 EnergyPlus_Larges, 9.7ms\n",
            "Speed: 3.5ms preprocess, 9.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 571, Frame Objects: 0, Total Objects: 50\n",
            "Final Total Objects Counted: 50\n"
          ]
        }
      ]
    }
  ]
}